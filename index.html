---
layout: default
nav_active: index
title: Touché @ CLEF
description: Touché @ CLEF Argument Retrieval
---


<main class="uk-section">
        <div class="uk-container">
                <h2 class="uk-lead">Task</h2>
                <p class=" uk-text-left">
                        Decision making processes, be it at the societal or at the personal level, eventually come to a point where one side will challenge the other with a why-question, which is a prompt to justify one’s stance.
                        Thus, technologies for argument mining and argumentation processing are maturing at a rapid
                        pace, giving rise for the first time to argument retrieval. We invite to participate in the first lab on <strong>Argument Retrieval</strong> at CLEF 2020 featuring two subtasks: <br> <br>(1) retrieval in a focused argument collection to support argumentative conversations; <br> (2) retrieval in a generic web crawl to answer comparative questions with argumentative results. <br> <br>
                        The <strong>(1) subtask</strong> is motivated by the support of users who search for arguments directly, e.g., by supporting their stance, and targets argumentative conversations. The task is to retrieve arguments from the provided dataset of the focused crawl with content from online debate portals for the 50~given topics, covering a wide range of controversial issues. <br> <br>
                        The <strong>(2) subtask</strong> is motivated by the support of users in personal decisions from everyday life where it comes to making choices. The task is to retrieve documents from a general web crawl ClueWeb12 that help the users to answer their comparative question. We provide 50 such questions. <br> <br>
                        Should you have questions contact us via touche@webis.de.
                </p>
                <p>To register for either task: <a href="http://clef2020-labs-registration.dei.unipd.it/registrationForm.php">Register Now</a>.</p>
                <h2 class="uk-lead">Dates</h2>
                <p class="uk-text-left">
                        <strong>November 22, 2019:</strong> Training data available, competition begins.&nbsp; <br>
                        <strong>February 01, 2020:</strong> Submission system opens.<br>
                        <strong>TBA :</strong> Leader board (TIRA).<br><!--<a
                                href="#"
                                class="uk-text-bold" style="text-decoration:underline">Leader board (TIRA)</a><br>-->
                        <strong>TBA :</strong> Submission system closed, manual evaluation
                        begins.<br>
                </p>
                <p>The timezone of all deadlines is <a href="https://en.wikipedia.org/wiki/Anywhere_on_Earth">Anywhere on Earth</a>.</p>
                <h2 class="uk-lead">Data</h2>
                <p class="uk-text-left">Will be added on November 22. <br></p>

                <h2 class="uk-lead">Evaluation</h2>
                <p class="uk-text-left">
                        Will be added soon.
                        <!-- 
                        To provide fast approximations of model performance, the public leaderboard
                        will be
                        updated with <a href="https://github.com/tagucci/pythonrouge" style="text-decoration:underline"
                                class="uk-text-bold">ROUGE</a> scores.
                        You will be able to self-evaluate your software using the <a href="http://tira.io/" target="new"
                                style="text-decoration:underline" class="uk-text-bold">TIRA</a>
                        service. You can find the user guide <a href="https://www.tira.io/static/tira-vm-user-guide.pdf"
                                style="text-decoration:underline" target="new" class="uk-text-bold">here</a>. &nbsp; Additionally, a qualitative evaluation will be performed through crowdsourcing. Human
                                annotators will rate each candidate summary according to five linguistic qualities as suggested
                                by the <a href="https://duc.nist.gov/pubs/2006papers/duc2006.pdf" target="new"
                                        style="text-decoration:underline" class="uk-text-bold">DUC
                                        guidelines</a>. -->
                </p>
                <h2 id="index-program">Program</h2>
                        The workshop program will be announced closer to the conference.

            <h2 id="index-organizing-committee">Organizing Committee</h2>
            <div data-uk-grid class="uk-grid uk-grid-match uk-grid-small thumbnail-card-grid">
                {% include people-cards/bondarenko.html %}
                {% include people-cards/hagen.html %}
                {% include people-cards/potthast.html %}
                {% include people-cards/wachsmuth.html %}
                {% include people-cards/beloucif.html %}
                {% include people-cards/bieman.html %}
                {% include people-cards/panchenko.html %}
                {% include people-cards/stein.html %}
            </div>
            <div class="uk-container uk-padding-large uk-padding-remove-bottom">
                {% include organizations/clef-organizations-section.html year=2020 %}
            </div>
        </div>
</main>
